{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b00d438d-d01c-4039-978b-78b2077ae94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp313-cp313-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from torch) (4.13.0)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from torch) (78.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "     ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "     ---------------------------- ----------- 4.5/6.2 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.2/6.2 MB 20.1 MB/s eta 0:00:00\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 536.2/536.2 kB 30.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.6.0%2Bcpu-cp313-cp313-win_amd64.whl (206.5 MB)\n",
      "   ---------------------------------------- 0.0/206.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 4.7/206.5 MB 28.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 7.6/206.5 MB 18.0 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 10.5/206.5 MB 16.9 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 14.4/206.5 MB 17.1 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 18.1/206.5 MB 17.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 22.0/206.5 MB 17.2 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 25.4/206.5 MB 17.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 29.4/206.5 MB 17.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 33.0/206.5 MB 17.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 36.7/206.5 MB 17.4 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 40.1/206.5 MB 17.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 43.5/206.5 MB 17.4 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 47.2/206.5 MB 17.4 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 51.1/206.5 MB 17.4 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 54.5/206.5 MB 17.4 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 58.5/206.5 MB 17.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 62.9/206.5 MB 17.4 MB/s eta 0:00:09\n",
      "   ------------ --------------------------- 66.6/206.5 MB 17.4 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 70.3/206.5 MB 17.4 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 73.9/206.5 MB 17.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 77.9/206.5 MB 17.4 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 81.5/206.5 MB 17.4 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 84.9/206.5 MB 17.4 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 87.6/206.5 MB 17.2 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 90.2/206.5 MB 17.0 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 93.1/206.5 MB 16.9 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 95.7/206.5 MB 16.7 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 98.0/206.5 MB 16.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 98.8/206.5 MB 16.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 100.4/206.5 MB 15.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 102.8/206.5 MB 15.7 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 105.4/206.5 MB 15.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 108.5/206.5 MB 15.6 MB/s eta 0:00:07\n",
      "   --------------------- ----------------- 113.2/206.5 MB 15.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 117.2/206.5 MB 15.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 120.8/206.5 MB 15.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 124.8/206.5 MB 15.9 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 128.2/206.5 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 132.1/206.5 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 135.8/206.5 MB 16.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 139.5/206.5 MB 16.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 143.1/206.5 MB 16.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 146.8/206.5 MB 16.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 150.7/206.5 MB 16.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 154.4/206.5 MB 16.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 158.1/206.5 MB 16.2 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 162.0/206.5 MB 16.2 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 165.7/206.5 MB 16.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 169.3/206.5 MB 16.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 173.0/206.5 MB 16.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 176.9/206.5 MB 16.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 180.6/206.5 MB 16.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 184.5/206.5 MB 16.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 188.0/206.5 MB 16.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 191.6/206.5 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 195.3/206.5 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 198.7/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.6/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  206.0/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  206.3/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  206.3/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  206.3/206.5 MB 16.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 206.5/206.5 MB 15.7 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchvision-0.21.0%2Bcpu-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 20.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.6.0%2Bcpu-cp313-cp313-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.7 MB/s eta 0:00:00\n",
      "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 19.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.6.1 mpmath-1.3.0 networkx-3.3 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cpu torchaudio-2.6.0+cpu torchvision-0.21.0+cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\sripa\\aasist_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\sripa\\aasist_env\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\sripa\\aasist_env\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sripa\\aasist_env\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (4.13.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: standard-sunau in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from librosa) (3.13.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Requirement already satisfied: packaging in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from standard-aifc->librosa) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from standard-aifc->librosa) (0.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sripa\\aasist_env\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies directly from Jupyter Notebook\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install tqdm librosa soundfile scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0327d71-735d-4563-938b-5e87696a9b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Streaming .tar:   0%|▎                                                                         | 27.8M/6.65G [00:03<14:57, 7.38MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamed 200 `.flac` files successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 2: Stream `.flac` files\n",
    "def stream_flac_files_in_memory(tar_url, limit=200):\n",
    "    \"\"\"\n",
    "    Stream a .tar archive and store `.flac` files in memory.\n",
    "    \n",
    "    Parameters:\n",
    "        tar_url (str): URL of the .tar file.\n",
    "        limit (int): Number of `.flac` files to process.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of tuples containing (filename, audio_data).\n",
    "    \"\"\"\n",
    "    response = requests.get(tar_url, stream=True, timeout=30)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Failed to download TAR archive: {tar_url} (Status code: {response.status_code})\")\n",
    "    \n",
    "    # Track progress\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    progress = tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Streaming .tar\")\n",
    "\n",
    "    extracted_files = []\n",
    "    extracted_count = 0\n",
    "\n",
    "    # Process the `.tar` file\n",
    "    with tarfile.open(fileobj=response.raw, mode=\"r|\") as archive:\n",
    "        for member in archive:\n",
    "            if member.name.endswith(\".flac\"):  # Only `.flac` files\n",
    "                flac_file = archive.extractfile(member)\n",
    "                if flac_file:\n",
    "                    audio_data = flac_file.read()\n",
    "                    extracted_files.append((member.name, audio_data))\n",
    "                    extracted_count += 1\n",
    "                    if extracted_count >= limit:\n",
    "                        break\n",
    "            progress.update(member.size)\n",
    "\n",
    "    progress.close()\n",
    "    return extracted_files\n",
    "\n",
    "# Example Usage: Stream the ASVspoof 5 dataset\n",
    "zenodo_url = \"https://zenodo.org/api/records/14498691\"\n",
    "response = requests.get(zenodo_url).json()\n",
    "file_urls = [file['links']['self'] for file in response['files']]\n",
    "tar_urls = [url for url in file_urls if url.endswith(\".tar/content\")]\n",
    "\n",
    "# Stream the first .tar file\n",
    "flac_files = stream_flac_files_in_memory(tar_urls[0], limit=200)\n",
    "print(f\"Streamed {len(flac_files)} `.flac` files successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4425807-46a7-4281-87f9-6957d378806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated 200 files successfully!\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "# Debug and refine validation process\n",
    "def debug_and_validate_audio(file_name, audio_data):\n",
    "    \"\"\"\n",
    "    Debug and validate audio files.\n",
    "    \n",
    "    Parameters:\n",
    "        file_name (str): Name of the audio file.\n",
    "        audio_data (bytes): Raw audio data.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Validated audio array, or None if validation fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Decode audio using PySoundFile\n",
    "        with sf.SoundFile(io.BytesIO(audio_data)) as f:\n",
    "            audio = f.read(dtype='float32')\n",
    "            sample_rate = f.samplerate\n",
    "\n",
    "        # Ensure audio contains finite values\n",
    "        if not np.all(np.isfinite(audio)):\n",
    "            raise ValueError(\"Audio contains non-finite values.\")\n",
    "\n",
    "        return audio, sample_rate\n",
    "    except Exception as e:\n",
    "        print(f\"Validation/Debug Error for {file_name}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Debug and validate all files\n",
    "validated_files = []\n",
    "for file_name, audio_data in flac_files:\n",
    "    validated_audio, sample_rate = debug_and_validate_audio(file_name, audio_data)\n",
    "    if validated_audio is not None:\n",
    "        validated_files.append((file_name, validated_audio, sample_rate))\n",
    "\n",
    "print(f\"Validated {len(validated_files)} files successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f55cd6b-0435-4678-a1a7-9992fcc7f2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted MFCC features for 200 files successfully!\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "# Step 4: Extract MFCC features from validated audio\n",
    "def extract_mfcc_features(audio_data, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from audio data.\n",
    "    \n",
    "    Parameters:\n",
    "        audio_data (np.array): Validated audio array.\n",
    "        sample_rate (int): Sampling rate for MFCC feature extraction.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: Mean MFCC feature array, or None if extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract 13 MFCCs\n",
    "        mfcc = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=13)\n",
    "        return np.mean(mfcc, axis=1)\n",
    "    except Exception as e:\n",
    "        print(f\"MFCC Extraction Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract MFCCs for all validated files\n",
    "features = []\n",
    "for file_name, audio_data, sample_rate in validated_files:\n",
    "    mfcc_features = extract_mfcc_features(audio_data, sample_rate=sample_rate)\n",
    "    if mfcc_features is not None:\n",
    "        features.append((file_name, mfcc_features))\n",
    "\n",
    "print(f\"Extracted MFCC features for {len(features)} files successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5514c694-3ceb-4b43-b2c7-e434b5012bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared datasets: 160 training samples, 40 testing samples.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Step 5: Define a custom dataset class\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with features and labels.\n",
    "\n",
    "        Parameters:\n",
    "            features (list): List of MFCC feature arrays.\n",
    "            labels (list): List of binary labels (0 for real, 1 for spoof).\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch a single item (feature, label) by index.\n",
    "\n",
    "        Parameters:\n",
    "            idx (int): Index of the item.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Feature tensor and label tensor.\n",
    "        \"\"\"\n",
    "        return torch.tensor(self.features[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "\n",
    "# Create mock labels (binary classification: 0 = real, 1 = spoof)\n",
    "# Replace these with actual labels if available\n",
    "labels = [random.randint(0, 1) for _ in range(len(features))]\n",
    "\n",
    "# Instantiate the dataset\n",
    "audio_dataset = AudioDataset(\n",
    "    features=[feature[1] for feature in features],  # Extract MFCC arrays\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "train_size = int(0.8 * len(audio_dataset))\n",
    "test_size = len(audio_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(audio_dataset, [train_size, test_size])\n",
    "\n",
    "# Prepare dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Prepared datasets: {len(train_dataset)} training samples, {len(test_dataset)} testing samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6865b29e-c925-4656-b0a5-29f5b0253914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AASIST(\n",
      "  (fc1): Linear(in_features=13, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Step 6: Define AASIST model\n",
    "class AASIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AASIST, self).__init__()\n",
    "        # Input size: 13 (number of MFCC features)\n",
    "        self.fc1 = nn.Linear(13, 64)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(64, 32)  # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(32, 1)   # Output layer (binary classification)\n",
    "        self.dropout = nn.Dropout(0.2)  # Dropout for regularization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(torch.relu(self.fc2(x)))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = AASIST()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b683b202-d16d-4601-8339-89c3119dab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.3237\n",
      "Epoch 2/10, Loss: 1.3685\n",
      "Epoch 3/10, Loss: 1.4789\n",
      "Epoch 4/10, Loss: 1.0559\n",
      "Epoch 5/10, Loss: 1.0488\n",
      "Epoch 6/10, Loss: 0.8370\n",
      "Epoch 7/10, Loss: 0.8104\n",
      "Epoch 8/10, Loss: 0.8543\n",
      "Epoch 9/10, Loss: 0.8967\n",
      "Epoch 10/10, Loss: 0.7870\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train the AASIST model\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
    "    \"\"\"\n",
    "    Train the AASIST model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (nn.Module): AASIST model to train.\n",
    "        dataloader (DataLoader): Training data loader.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimization algorithm.\n",
    "        epochs (int): Number of training epochs.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs.squeeze(), labels)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "            epoch_loss += loss.item()  # Accumulate loss\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "# Initialize loss function, optimizer, and train the model\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2a3beac-3e88-44c9-8e40-dc94c54e2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.5893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Step 8: Evaluate the AASIST model\n",
    "def evaluate_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate the AASIST model using AUC-ROC metric.\n",
    "    \n",
    "    Parameters:\n",
    "        model (nn.Module): Trained AASIST model.\n",
    "        dataloader (DataLoader): Testing data loader.\n",
    "    \n",
    "    Returns:\n",
    "        float: AUC score for evaluation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs).squeeze()  # Forward pass\n",
    "            all_preds.extend(outputs.numpy())  # Collect predictions\n",
    "            all_labels.extend(labels.numpy())  # Collect true labels\n",
    "    \n",
    "    # Compute AUC-ROC score\n",
    "    auc_score = roc_auc_score(all_labels, all_preds)\n",
    "    print(f\"AUC Score: {auc_score:.4f}\")\n",
    "    return auc_score\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_auc = evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
